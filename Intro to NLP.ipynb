{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34cbed95-62f2-4236-86d3-0b071be03f25",
   "metadata": {},
   "source": [
    "# Introduction to NLP preprocessing and encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9350f-03ce-45d7-910d-f78435377d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8f4bb-5d7d-42b4-952a-d7cd246d461f",
   "metadata": {},
   "source": [
    "For this first section, we will be running through some common preprocessing steps. Remember, preprocessing should be based on your data and use case, not a one size fits all approach.\n",
    "\n",
    "We will be using a subsample of Twitter data from this dataset: https://www.kaggle.com/datasets/monogenea/game-of-thrones-twitter?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f931215a-e2a0-41e0-b307-c755d05c85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# read in the gotTwitter dataset we will be working with\n",
    "got_data = pd.read_csv('gotTwitter.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3acdbd9e-9450-4fc5-9067-5b4f37b7581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Over 370,000 'Game of Thrones' fans sign petition for remake of season 8 https://t.co/jqxWu4E5k3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>With both Game of Thrones and The Big Bang Theory ending this week, I&lt;U+2019&gt;m wondering if it would be fun to take hugely-popular, long-running, juggernaut shows I&lt;U+2019&gt;ve never seen a single episode of, and watch JUST the finale, and see what I think?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Suddenly, last episode, Daenerys embraced the thrill of genocide, specifically targeting civilians with dragon fire. Personality changes happen in fiction, but not with such lack of subtlety -- not to characters @GameOfThrones respect and understand.\\n\\n https://t.co/FR9HzLcGB0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Sprinkles causes a stampede by releasing a limited-time-only &lt;U+2018&gt;Game of Thrones&lt;U+2019&gt; dragon fruit cupcake sold Friday, May 17-Sunday, May 19 https://t.co/9zNhC00Sj4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>&lt;U+2018&gt;Game of Thrones&lt;U+2019&gt; is airing its final episode, and here&lt;U+2019&gt;s what we&lt;U+2019&gt;ll miss when it ends https://t.co/Adb12iWRqb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                     text  \n",
       "0                                                                                                                                                                                        Over 370,000 'Game of Thrones' fans sign petition for remake of season 8 https://t.co/jqxWu4E5k3  \n",
       "1                         With both Game of Thrones and The Big Bang Theory ending this week, I<U+2019>m wondering if it would be fun to take hugely-popular, long-running, juggernaut shows I<U+2019>ve never seen a single episode of, and watch JUST the finale, and see what I think?  \n",
       "2  Suddenly, last episode, Daenerys embraced the thrill of genocide, specifically targeting civilians with dragon fire. Personality changes happen in fiction, but not with such lack of subtlety -- not to characters @GameOfThrones respect and understand.\\n\\n https://t.co/FR9HzLcGB0  \n",
       "3                                                                                                            Sprinkles causes a stampede by releasing a limited-time-only <U+2018>Game of Thrones<U+2019> dragon fruit cupcake sold Friday, May 17-Sunday, May 19 https://t.co/9zNhC00Sj4  \n",
       "4                                                                                                                                              <U+2018>Game of Thrones<U+2019> is airing its final episode, and here<U+2019>s what we<U+2019>ll miss when it ends https://t.co/Adb12iWRqb  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set_option to view full column in notebook\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# make sure it loaded correctly, there should be 3 columns, an id number, a created_at date, and the text of the tweets\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd9ae1-0b55-493d-a709-7099f825a9bd",
   "metadata": {},
   "source": [
    "#### Remove things like special characters, symbols, punctuation, URLs, etc. from the data that contains little information for a model to learn and are often primarily noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd5ca79-1d50-438b-aef3-6dc1cb4dbb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string #import packages for regex replacement\n",
    "\n",
    "def clean_text_round(row):\n",
    "    row = re.sub(r'http\\S+', '', row) #remove urls\n",
    "    row = re.sub(r\"(?<![@\\w])@(\\w{1,25})\", '', row) #remove mentions\n",
    "    return row\n",
    "\n",
    "clean = lambda x: clean_text_round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdce03e-6efd-4e37-9fd7-4a0ec5dac6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Over 370,000 'Game of Thrones' fans sign petition for remake of season 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>With both Game of Thrones and The Big Bang Theory ending this week, I&lt;U+2019&gt;m wondering if it would be fun to take hugely-popular, long-running, juggernaut shows I&lt;U+2019&gt;ve never seen a single episode of, and watch JUST the finale, and see what I think?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Suddenly, last episode, Daenerys embraced the thrill of genocide, specifically targeting civilians with dragon fire. Personality changes happen in fiction, but not with such lack of subtlety -- not to characters  respect and understand.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Sprinkles causes a stampede by releasing a limited-time-only &lt;U+2018&gt;Game of Thrones&lt;U+2019&gt; dragon fruit cupcake sold Friday, May 17-Sunday, May 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>&lt;U+2018&gt;Game of Thrones&lt;U+2019&gt; is airing its final episode, and here&lt;U+2019&gt;s what we&lt;U+2019&gt;ll miss when it ends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                                              text  \n",
       "0                                                                                                                                                                                        Over 370,000 'Game of Thrones' fans sign petition for remake of season 8   \n",
       "1  With both Game of Thrones and The Big Bang Theory ending this week, I<U+2019>m wondering if it would be fun to take hugely-popular, long-running, juggernaut shows I<U+2019>ve never seen a single episode of, and watch JUST the finale, and see what I think?  \n",
       "2                Suddenly, last episode, Daenerys embraced the thrill of genocide, specifically targeting civilians with dragon fire. Personality changes happen in fiction, but not with such lack of subtlety -- not to characters  respect and understand.\\n\\n   \n",
       "3                                                                                                            Sprinkles causes a stampede by releasing a limited-time-only <U+2018>Game of Thrones<U+2019> dragon fruit cupcake sold Friday, May 17-Sunday, May 19   \n",
       "4                                                                                                                                              <U+2018>Game of Thrones<U+2019> is airing its final episode, and here<U+2019>s what we<U+2019>ll miss when it ends   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function above across each row of the text column\n",
    "got_data.loc[:, 'text'] = got_data['text'].apply(clean)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171c272-0bcc-4b01-b62b-36ba006d2fb0",
   "metadata": {},
   "source": [
    "We can see there are still elements that appear noisy, let's add a line to our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30e5dd4-3d24-4083-97dd-9add2cc5fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added a new line\n",
    "def clean_text_round(row):\n",
    "    row = re.sub(r'http\\S+', '', row) #remove urls\n",
    "    row = re.sub(r\"(?<![@\\w])@(\\w{1,25})\", '', row) #remove mentions\n",
    "    row = re.sub(r\"<[^>]+>\", '', row) # remove carrot inserts from collection <---- new operation\n",
    "    return row\n",
    "\n",
    "clean = lambda x: clean_text_round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef403660-708f-4b08-9be6-48ebb32f75ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Over 370,000 'Game of Thrones' fans sign petition for remake of season 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>With both Game of Thrones and The Big Bang Theory ending this week, Im wondering if it would be fun to take hugely-popular, long-running, juggernaut shows Ive never seen a single episode of, and watch JUST the finale, and see what I think?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Suddenly, last episode, Daenerys embraced the thrill of genocide, specifically targeting civilians with dragon fire. Personality changes happen in fiction, but not with such lack of subtlety -- not to characters  respect and understand.\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Sprinkles causes a stampede by releasing a limited-time-only Game of Thrones dragon fruit cupcake sold Friday, May 17-Sunday, May 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>Game of Thrones is airing its final episode, and heres what well miss when it ends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                                text  \n",
       "0                                                                                                                                                                          Over 370,000 'Game of Thrones' fans sign petition for remake of season 8   \n",
       "1    With both Game of Thrones and The Big Bang Theory ending this week, Im wondering if it would be fun to take hugely-popular, long-running, juggernaut shows Ive never seen a single episode of, and watch JUST the finale, and see what I think?  \n",
       "2  Suddenly, last episode, Daenerys embraced the thrill of genocide, specifically targeting civilians with dragon fire. Personality changes happen in fiction, but not with such lack of subtlety -- not to characters  respect and understand.\\n\\n   \n",
       "3                                                                                                              Sprinkles causes a stampede by releasing a limited-time-only Game of Thrones dragon fruit cupcake sold Friday, May 17-Sunday, May 19   \n",
       "4                                                                                                                                                                Game of Thrones is airing its final episode, and heres what well miss when it ends   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function above across each row of the text column\n",
    "got_data.loc[:, 'text'] = got_data['text'].apply(clean)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c574b-918a-4612-bc18-fa45e141dc9b",
   "metadata": {},
   "source": [
    "Much better! What other cleaning steps might you take here? Add a line to the function for additional cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74461168-ffa8-401f-99dd-5b3f7f8e2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def clean_new_line(row):\n",
    "    row = row.replace(\"\\n\",\"\")\n",
    "    row = re.sub(r'[^\\w\\s]', '', row)\n",
    "    return row\n",
    "\n",
    "new_line_clean = lambda x: clean_new_line(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a6738e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Over 370000 Game of Thrones fans sign petition for remake of season 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>With both Game of Thrones and The Big Bang Theory ending this week Im wondering if it would be fun to take hugelypopular longrunning juggernaut shows Ive never seen a single episode of and watch JUST the finale and see what I think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Suddenly last episode Daenerys embraced the thrill of genocide specifically targeting civilians with dragon fire Personality changes happen in fiction but not with such lack of subtlety  not to characters  respect and understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>Sprinkles causes a stampede by releasing a limitedtimeonly Game of Thrones dragon fruit cupcake sold Friday May 17Sunday May 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>Game of Thrones is airing its final episode and heres what well miss when it ends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                      text  \n",
       "0                                                                                                                                                                   Over 370000 Game of Thrones fans sign petition for remake of season 8   \n",
       "1  With both Game of Thrones and The Big Bang Theory ending this week Im wondering if it would be fun to take hugelypopular longrunning juggernaut shows Ive never seen a single episode of and watch JUST the finale and see what I think  \n",
       "2    Suddenly last episode Daenerys embraced the thrill of genocide specifically targeting civilians with dragon fire Personality changes happen in fiction but not with such lack of subtlety  not to characters  respect and understand   \n",
       "3                                                                                                         Sprinkles causes a stampede by releasing a limitedtimeonly Game of Thrones dragon fruit cupcake sold Friday May 17Sunday May 19   \n",
       "4                                                                                                                                                       Game of Thrones is airing its final episode and heres what well miss when it ends   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_data.loc[:, 'text'] = got_data['text'].apply(new_line_clean)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332f8f1-978d-4e0a-949b-84f6c412f73b",
   "metadata": {},
   "source": [
    "#### Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079eb5c8-ed39-47ea-b7ae-d8183a5267b8",
   "metadata": {},
   "source": [
    "There are many ways to lowercase your data, here we use re, feel free to drop in your new lines as we redefine the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab32be2-a96a-41ca-b509-1d1a55660d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added a new line\n",
    "def clean_text_round(row):\n",
    "    row = row.lower() # make lowercase  <---- new operation\n",
    "    row = re.sub(r'http\\S+', '', row) #remove urls\n",
    "    row = re.sub(r\"(?<![@\\w])@(\\w{1,25})\", '', row) #remove mentions\n",
    "    row = re.sub(r\"<[^>]+>\", '', row) # remove carrot inserts from collection\n",
    "    return row\n",
    "\n",
    "clean = lambda x: clean_text_round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebfaf320-00d5-4923-84ab-1ff6a9d4532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>over 370000 game of thrones fans sign petition for remake of season 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>with both game of thrones and the big bang theory ending this week im wondering if it would be fun to take hugelypopular longrunning juggernaut shows ive never seen a single episode of and watch just the finale and see what i think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>suddenly last episode daenerys embraced the thrill of genocide specifically targeting civilians with dragon fire personality changes happen in fiction but not with such lack of subtlety  not to characters  respect and understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>sprinkles causes a stampede by releasing a limitedtimeonly game of thrones dragon fruit cupcake sold friday may 17sunday may 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>game of thrones is airing its final episode and heres what well miss when it ends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                      text  \n",
       "0                                                                                                                                                                   over 370000 game of thrones fans sign petition for remake of season 8   \n",
       "1  with both game of thrones and the big bang theory ending this week im wondering if it would be fun to take hugelypopular longrunning juggernaut shows ive never seen a single episode of and watch just the finale and see what i think  \n",
       "2    suddenly last episode daenerys embraced the thrill of genocide specifically targeting civilians with dragon fire personality changes happen in fiction but not with such lack of subtlety  not to characters  respect and understand   \n",
       "3                                                                                                         sprinkles causes a stampede by releasing a limitedtimeonly game of thrones dragon fruit cupcake sold friday may 17sunday may 19   \n",
       "4                                                                                                                                                       game of thrones is airing its final episode and heres what well miss when it ends   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_data.loc[:, 'text'] = got_data['text'].apply(clean)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c4958-26e6-4013-a17c-3da639447af4",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe12340-f4e7-4e97-b796-37aea5551377",
   "metadata": {},
   "source": [
    "Again, there are many ways to tokenize. The package NLTK has built in functions to help us tokenize in different ways, including by word and by sentence. Here, we tokenize using a special tweet tokenizer that is able to take things like emojis into account. Read the documentation here: https://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69915ef9-f53b-47bb-a689-c14f12dc9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "\n",
    "# define a function that we can apply over our data\n",
    "def tweet_tokenize(row):\n",
    "    row = tweet_tokenizer.tokenize(row)\n",
    "    return row\n",
    "\n",
    "tokenized = lambda x: tweet_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9378e6b2-88a9-41a8-ab6e-d32d4bcf7575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[over, 370000, game, of, thrones, fans, sign, petition, for, remake, of, season, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[with, both, game, of, thrones, and, the, big, bang, theory, ending, this, week, im, wondering, if, it, would, be, fun, to, take, hugelypopular, longrunning, juggernaut, shows, ive, never, seen, a, single, episode, of, and, watch, just, the, finale, and, see, what, i, think]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[suddenly, last, episode, daenerys, embraced, the, thrill, of, genocide, specifically, targeting, civilians, with, dragon, fire, personality, changes, happen, in, fiction, but, not, with, such, lack, of, subtlety, not, to, characters, respect, and, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[sprinkles, causes, a, stampede, by, releasing, a, limitedtimeonly, game, of, thrones, dragon, fruit, cupcake, sold, friday, may, 17sunday, may, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>[game, of, thrones, is, airing, its, final, episode, and, heres, what, well, miss, when, it, ends]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                  text  \n",
       "0                                                                                                                                                                                                  [over, 370000, game, of, thrones, fans, sign, petition, for, remake, of, season, 8]  \n",
       "1  [with, both, game, of, thrones, and, the, big, bang, theory, ending, this, week, im, wondering, if, it, would, be, fun, to, take, hugelypopular, longrunning, juggernaut, shows, ive, never, seen, a, single, episode, of, and, watch, just, the, finale, and, see, what, i, think]  \n",
       "2                 [suddenly, last, episode, daenerys, embraced, the, thrill, of, genocide, specifically, targeting, civilians, with, dragon, fire, personality, changes, happen, in, fiction, but, not, with, such, lack, of, subtlety, not, to, characters, respect, and, understand]  \n",
       "3                                                                                                                                 [sprinkles, causes, a, stampede, by, releasing, a, limitedtimeonly, game, of, thrones, dragon, fruit, cupcake, sold, friday, may, 17sunday, may, 19]  \n",
       "4                                                                                                                                                                                   [game, of, thrones, is, airing, its, final, episode, and, heres, what, well, miss, when, it, ends]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_data.loc[:, 'text'] = got_data['text'].apply(tokenized)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a684f98-0a0c-44d5-a742-18adf9c806f0",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367b9cf1-1434-4681-bcfe-ec1a6824ce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saahi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') # download the list of stopwords from nltk if you have not done this before\n",
    "from nltk.corpus import stopwords # import stopwords\n",
    "\n",
    "stopeng = set(stopwords.words('english')) #set language\n",
    "\n",
    "#define a function to remove stopwords\n",
    "def remove_stopwords(row):\n",
    "    row = [w for w in row if w not in stopeng]\n",
    "    return row\n",
    "\n",
    "no_stopwords = lambda x: remove_stopwords(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a6473f-6108-4fbc-8801-526cac47a96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[370000, game, thrones, fans, sign, petition, remake, season, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[game, thrones, big, bang, theory, ending, week, im, wondering, would, fun, take, hugelypopular, longrunning, juggernaut, shows, ive, never, seen, single, episode, watch, finale, see, think]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[suddenly, last, episode, daenerys, embraced, thrill, genocide, specifically, targeting, civilians, dragon, fire, personality, changes, happen, fiction, lack, subtlety, characters, respect, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>[sprinkles, causes, stampede, releasing, limitedtimeonly, game, thrones, dragon, fruit, cupcake, sold, friday, may, 17sunday, may, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>[game, thrones, airing, final, episode, heres, well, miss, ends]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                        text  \n",
       "0                                                                                                                                           [370000, game, thrones, fans, sign, petition, remake, season, 8]  \n",
       "1             [game, thrones, big, bang, theory, ending, week, im, wondering, would, fun, take, hugelypopular, longrunning, juggernaut, shows, ive, never, seen, single, episode, watch, finale, see, think]  \n",
       "2  [suddenly, last, episode, daenerys, embraced, thrill, genocide, specifically, targeting, civilians, dragon, fire, personality, changes, happen, fiction, lack, subtlety, characters, respect, understand]  \n",
       "3                                                                     [sprinkles, causes, stampede, releasing, limitedtimeonly, game, thrones, dragon, fruit, cupcake, sold, friday, may, 17sunday, may, 19]  \n",
       "4                                                                                                                                           [game, thrones, airing, final, episode, heres, well, miss, ends]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_data.loc[:, 'text'] = got_data['text'].apply(no_stopwords)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca399d0-12d3-4ca6-9bc8-960a88748008",
   "metadata": {},
   "source": [
    "What do you notice about our data as we add additional preprocessing? How do you think this will impact our analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78310327",
   "metadata": {},
   "source": [
    "Human interpretation is lost, however the data becomes more machine-readable to make better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d8b09-1ef7-493c-9d70-8b02dfde8312",
   "metadata": {},
   "source": [
    "#### Lemmatization/Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579a621-8536-421c-9d89-81f65b58bbb2",
   "metadata": {},
   "source": [
    "We'll start with lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78feee6d-078f-4e1a-beb0-e9ec283c31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saahi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\saahi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet') # you may need to run these depending on your setup\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "# define function to lemmatize\n",
    "def lemmatize(row):\n",
    "    row = [lmtzr.lemmatize(token) for token in row]\n",
    "    row = ' '.join(row) # this is the final step of our guided walkthrough, so I have re-joined the tweets into single documents instead of lists\n",
    "    return row\n",
    "\n",
    "lemmatized = lambda x: lemmatize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae4e1c6-edc0-4595-af49-ca602ae8d30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>370000 game throne fan sign petition remake season 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>game throne big bang theory ending week im wondering would fun take hugelypopular longrunning juggernaut show ive never seen single episode watch finale see think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>suddenly last episode daenerys embraced thrill genocide specifically targeting civilian dragon fire personality change happen fiction lack subtlety character respect understand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>sprinkle cause stampede releasing limitedtimeonly game throne dragon fruit cupcake sold friday may 17sunday may 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>game throne airing final episode here well miss end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                               text  \n",
       "0                                                                                                                              370000 game throne fan sign petition remake season 8  \n",
       "1                game throne big bang theory ending week im wondering would fun take hugelypopular longrunning juggernaut show ive never seen single episode watch finale see think  \n",
       "2  suddenly last episode daenerys embraced thrill genocide specifically targeting civilian dragon fire personality change happen fiction lack subtlety character respect understand  \n",
       "3                                                                sprinkle cause stampede releasing limitedtimeonly game throne dragon fruit cupcake sold friday may 17sunday may 19  \n",
       "4                                                                                                                               game throne airing final episode here well miss end  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_data.loc[:, 'text'] = got_data['text'].apply(lemmatized)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b20c4f-e3df-4eb4-9700-c6bb5101aaf2",
   "metadata": {},
   "source": [
    "How would you apply stemming? Hint: https://www.nltk.org/howto/stem.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3df92b0-21da-4699-976f-3ebc7466858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(row):\n",
    "    row = [stemmer.stem(token) for token in row]\n",
    "    row = ' '.join(row)\n",
    "    return row\n",
    "\n",
    "stemmed = lambda x: stemming(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4d93ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1129144346618540033</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>3 7 0 0 0 0   g a m e   t h r o n e   f a n   s i g n   p e t i t i o n   r e m a k e   s e a s o n   8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1129144306206298112</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>g a m e   t h r o n e   b i g   b a n g   t h e o r y   e n d i n g   w e e k   i m   w o n d e r i n g   w o u l d   f u n   t a k e   h u g e l y p o p u l a r   l o n g r u n n i n g   j u g g e r n a u t   s h o w   i v e   n e v e r   s e e n   s i n g l e   e p i s o d e   w a t c h   f i n a l e   s e e   t h i n k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1129144249205895171</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>s u d d e n l y   l a s t   e p i s o d e   d a e n e r y s   e m b r a c e d   t h r i l l   g e n o c i d e   s p e c i f i c a l l y   t a r g e t i n g   c i v i l i a n   d r a g o n   f i r e   p e r s o n a l i t y   c h a n g e   h a p p e n   f i c t i o n   l a c k   s u b t l e t y   c h a r a c t e r   r e s p e c t   u n d e r s t a n d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1129144246869663745</td>\n",
       "      <td>5/16/2019 21:59</td>\n",
       "      <td>s p r i n k l e   c a u s e   s t a m p e d e   r e l e a s i n g   l i m i t e d t i m e o n l y   g a m e   t h r o n e   d r a g o n   f r u i t   c u p c a k e   s o l d   f r i d a y   m a y   1 7 s u n d a y   m a y   1 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1129141956095954956</td>\n",
       "      <td>5/16/2019 21:49</td>\n",
       "      <td>g a m e   t h r o n e   a i r i n g   f i n a l   e p i s o d e   h e r e   w e l l   m i s s   e n d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              status_id       created_at  \\\n",
       "0  x1129144346618540033  5/16/2019 21:59   \n",
       "1  x1129144306206298112  5/16/2019 21:59   \n",
       "2  x1129144249205895171  5/16/2019 21:59   \n",
       "3  x1129144246869663745  5/16/2019 21:59   \n",
       "4  x1129141956095954956  5/16/2019 21:49   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                              text  \n",
       "0                                                                                                                                                                                                                                                          3 7 0 0 0 0   g a m e   t h r o n e   f a n   s i g n   p e t i t i o n   r e m a k e   s e a s o n   8  \n",
       "1                              g a m e   t h r o n e   b i g   b a n g   t h e o r y   e n d i n g   w e e k   i m   w o n d e r i n g   w o u l d   f u n   t a k e   h u g e l y p o p u l a r   l o n g r u n n i n g   j u g g e r n a u t   s h o w   i v e   n e v e r   s e e n   s i n g l e   e p i s o d e   w a t c h   f i n a l e   s e e   t h i n k  \n",
       "2  s u d d e n l y   l a s t   e p i s o d e   d a e n e r y s   e m b r a c e d   t h r i l l   g e n o c i d e   s p e c i f i c a l l y   t a r g e t i n g   c i v i l i a n   d r a g o n   f i r e   p e r s o n a l i t y   c h a n g e   h a p p e n   f i c t i o n   l a c k   s u b t l e t y   c h a r a c t e r   r e s p e c t   u n d e r s t a n d  \n",
       "3                                                                                                                              s p r i n k l e   c a u s e   s t a m p e d e   r e l e a s i n g   l i m i t e d t i m e o n l y   g a m e   t h r o n e   d r a g o n   f r u i t   c u p c a k e   s o l d   f r i d a y   m a y   1 7 s u n d a y   m a y   1 9  \n",
       "4                                                                                                                                                                                                                                                            g a m e   t h r o n e   a i r i n g   f i n a l   e p i s o d e   h e r e   w e l l   m i s s   e n d  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_data.loc[:, 'text'] = got_data['text'].apply(stemmed)\n",
    "got_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9d88f-f78d-4cd2-9861-93c6e7455624",
   "metadata": {},
   "source": [
    "If you have extra time: how might you split our data into ngrams? Hint: https://www.nltk.org/api/nltk.util.html#nltk.util.ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceb7adb1-d4e5-4753-a503-d6be0705790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bac9ab-fd5e-49eb-b452-c3b9fc83eff6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 2: Encoding Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa83ca-7839-4475-84f9-8a4396319646",
   "metadata": {},
   "source": [
    "#### BOW (bag of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978622f-25fb-4e62-99ed-fc56ac73a36d",
   "metadata": {},
   "source": [
    "Countvectorizer does all of the work for us, pay attention to the lecture to know what it does :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2bd3299-ae08-4c9c-8c91-75200edc2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll select a subset of data so we're not looking at massive representations\n",
    "data_list = got_data.iloc[:50]['text'].to_list()\n",
    "# data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d53225-bde6-4245-a21b-d7780b786eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create variable for vectorizer\n",
    "bow = CountVectorizer()\n",
    " \n",
    "# apply function on data subsample\n",
    "bow_result = bow.fit_transform(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886e03ee-5863-4c80-9e50-eafce6b446fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['throne' 'warfare' 'history' 'parallel' 'penultimate' 'classical' 'see'\n",
      " 'theory' 'dany' 'destroy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# feature names corresponds to our vocabulary in this case\n",
    "feature_array = np.array(bow.get_feature_names_out()) # get_feature_names_out is dependent on sklearn version, can also be get_feature_names_out\n",
    "bow_sorting = np.argsort(bow_result.toarray()).flatten()[::-1]\n",
    "\n",
    "# sorting by the top n features based on bow\n",
    "n = 10\n",
    "bow_top_n = feature_array[bow_sorting][:n]\n",
    "print(bow_top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5e315-0b04-4e46-8bd6-9750eba3677c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0fc47b-6ec0-4e9a-a44a-4725eb8fe9a4",
   "metadata": {},
   "source": [
    "Sklearn also has a module for tfidf, implemented below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e84ff90-33c4-43a8-b20c-a8e0eaabccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create variable for vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    " \n",
    "# apply function on data subsample\n",
    "tfidf_result = tfidf.fit_transform(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b70f6f2-a372-4159-afae-36e23c46e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queen' 'rain' 'warfare' 'parallel' 'penultimate' 'classical' 'dany'\n",
      " 'destroy' 'history' 'realworld']\n"
     ]
    }
   ],
   "source": [
    "feature_array = np.array(tfidf.get_feature_names_out()) # get_feature_names is dependent on sklearn version\n",
    "tfidf_sorting = np.argsort(tfidf_result.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 10\n",
    "tfidf_top_n = feature_array[tfidf_sorting][:n]\n",
    "print(tfidf_top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62040bf-e86b-417b-b50f-7d555c38edce",
   "metadata": {},
   "source": [
    "Why do you think the top N lists are different between BOW and TF-IDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6339d9d",
   "metadata": {},
   "source": [
    "The top N lists generated by Bag-of-Words (BOW) and Term Frequency-Inverse Document Frequency (TF-IDF) can be different because of the way they represent the text.\n",
    "\n",
    "BOW represents text as a collection of words and their frequencies in the document, without considering the order of the words. The frequency of each word in the document is used to generate a feature vector that represents the document. When generating the top N list using BOW, the most frequent words in the document will be ranked highest.\n",
    "\n",
    "TF-IDF also considers the importance of words in the document relative to their frequency in the corpus. It takes into account how often a word appears in the document and how rare it is in the corpus. Words that are common in the corpus but rare in the document are given a higher weight, as they are considered more important for characterizing the document. When generating the top N list using TF-IDF, the words that are most characteristic of the document will be ranked highest.\n",
    "\n",
    "Therefore, the top N lists generated by BOW and TF-IDF can be different because BOW only considers word frequency in the document, while TF-IDF considers the importance of words relative to their frequency in the corpus. This can result in different words being ranked highest in the two representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ae008-1973-47f6-a101-dcc1eff1dca0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 3: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9c6d5-0ce4-4f97-b6e3-e0a951cbb35b",
   "metadata": {},
   "source": [
    "For our word embedding exploration we will be using the gensim library. Gensim has pretrained embeddings for glove, word2vec, and fasttext, although we will only be playing around with word2vec.\n",
    "\n",
    "Here is some documentation: https://radimrehurek.com/gensim/models/word2vec.html, https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad24e0c2-eecd-4c4f-8341-fd9c32def80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65e3bcc8-e3fb-4c96-b854-c5b9c55d4a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this will load pretrained embeddings from word2vec based on google news data, it will take a little while to process so be patient\n",
    "w2v_google_news = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92dbf91e-550e-4ae3-9000-894494c65937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.9314123392105103),\n",
       " ('monarch', 0.858533501625061),\n",
       " ('princess', 0.8476566076278687),\n",
       " ('Queen_Consort', 0.8150269985198975),\n",
       " ('queens', 0.8099815249443054),\n",
       " ('crown_prince', 0.8089976906776428),\n",
       " ('royal_palace', 0.8027306795120239),\n",
       " ('monarchy', 0.8019613027572632),\n",
       " ('prince', 0.800979733467102),\n",
       " ('empress', 0.7958389520645142)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can run code for analogies, I have included the king - man, + woman = queen example to start\n",
    "w2v_google_news.most_similar_cosmul(positive=['king','woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcb3528a-036c-41bf-8015-61efaf10295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patriots', 0.6744824051856995),\n",
       " ('patriotic', 0.5867904424667358),\n",
       " ('statesman', 0.5711328387260437),\n",
       " ('constitutionalist', 0.5575802326202393),\n",
       " ('traitor', 0.5424764156341553),\n",
       " ('revolutionist', 0.5388073921203613),\n",
       " ('hero', 0.5304943323135376),\n",
       " ('ardent_patriot', 0.5239595174789429),\n",
       " ('patriotism', 0.5227564573287964),\n",
       " ('rabble_rouser', 0.5194998979568481)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing words similar to a single word\n",
    "w2v_google_news.most_similar('patriot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15cd0763-03a5-422a-a362-0748a3dd54de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869569361209869"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_google_news.distance('president', 'patriot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bc325-62a3-4b45-aad7-4545c6d936d1",
   "metadata": {},
   "source": [
    "Explore different word relationships using the tools above or commands from the linked documentation, what relationships seem surprising? Why might the model have embedded certain words in similar ways when linguistically we wouldn't expect them to be similar? Use at least one new example per method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fc401de-90ac-4fdd-9b17-f30d8ab1661d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computers', 0.7979379892349243),\n",
       " ('laptop', 0.6640493273735046),\n",
       " ('laptop_computer', 0.6548868417739868),\n",
       " ('Computer', 0.647333562374115),\n",
       " ('com_puter', 0.6082080006599426),\n",
       " ('technician_Leonard_Luchko', 0.5662748217582703),\n",
       " ('mainframes_minicomputers', 0.5617720484733582),\n",
       " ('laptop_computers', 0.5585449934005737),\n",
       " ('PC', 0.5539618730545044),\n",
       " ('maker_Dell_DELL.O', 0.5519254207611084)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "w2v_google_news.most_similar('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb97e608-4917-4b25-bee1-dccb28efd6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321875184774399"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your text answer here, in markdown\n",
    "w2v_google_news.distance('ball', 'sport')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a62888",
   "metadata": {},
   "source": [
    "Ball and Sport are similar, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef6f0648-6d02-45e3-aa1e-d0ed6e9e603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995845317840576"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_google_news.distance('student', 'dumb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5e4ee",
   "metadata": {},
   "source": [
    "In this example we would not expect student and dumb to be highly similar which is actually the case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
